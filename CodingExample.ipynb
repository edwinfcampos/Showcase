{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Objective:** Calculate the daily maximum wind speed (mph) for each Climate zone 1-9 (donâ€™t include the Central Valley). \n",
    "\n",
    "## Inputs:\n",
    "Using the WRF data and FDCZ (Fire Danger Climate zone) shapefile, \n",
    "\n",
    "Attached is the FDCZ shapefile (tar file), land/sea mask file (nc file),  and the WRF netCDF data for a random day\n",
    "\n",
    "## Outputs:\n",
    "Create a map displaying each climate zone color coded by the maximum daily wind speed.   can be found at the link below.\n",
    "\n",
    "Just to be clear, we are expecting a map of **maximum daily wind speed by zone** along with a file of the code you used to create that map.\n",
    "\n",
    "\n",
    "    Created by Edwin Campos, on 2020 Apr.23\n",
    "    Last modification on 2020 Apr.23 by ecampos.phd@gmail.com\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLOBAL VARIABLES\n",
    "WRF_FILE = 'wrf_daily_ts_2017-10-08.nc'\n",
    "MASK_FILE='invariant_d01.nc'\n",
    "SHAPE_PATH='./fdcz_pl/fdcz_pl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read NetCDF files\n",
    "\n",
    "References:\n",
    "\n",
    "    https://anaconda.org/anaconda/netcdf4\n",
    "    http://atmos.colostate.edu/~btrabing/Read_WRF.html\n",
    "    https://stackoverflow.com/questions/35297771/wrf-netcdf-file-subset-smaller-array-out-of-dataset-based-on-coordinate-bounda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input WRF dataset\n",
    "wrf_data = Dataset(WRF_FILE, \"r\")\n",
    "mask_data= Dataset(MASK_FILE, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('times', <class 'netCDF4._netCDF4.Variable'>\n",
      "|S1 times(Time, DateStrLen)\n",
      "unlimited dimensions: Time\n",
      "current shape = (24, 19)\n",
      "filling on, default _FillValue of \u0000 used\n",
      "), ('T2', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 T2(Time, south_north, west_east)\n",
      "    stagger: \n",
      "    coordinates: XLONG XLAT\n",
      "    units: K\n",
      "    description: TEMP at 2 M\n",
      "unlimited dimensions: Time\n",
      "current shape = (24, 320, 256)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('RH2', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 RH2(Time, south_north, west_east)\n",
      "    description: Near-sfc RH\n",
      "    units: %\n",
      "    stagger: \n",
      "    coordinates: XLONG XLAT\n",
      "unlimited dimensions: Time\n",
      "current shape = (24, 320, 256)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('U10', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 U10(Time, south_north, west_east)\n",
      "    stagger: \n",
      "    coordinates: XLONG XLAT\n",
      "    units: m s-1\n",
      "    description: U at 10m\n",
      "unlimited dimensions: Time\n",
      "current shape = (24, 320, 256)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('V10', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 V10(Time, south_north, west_east)\n",
      "    stagger: \n",
      "    coordinates: XLONG XLAT\n",
      "    units: m s-1\n",
      "    description: V at 10m\n",
      "unlimited dimensions: Time\n",
      "current shape = (24, 320, 256)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('SWDOWN', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 SWDOWN(Time, south_north, west_east)\n",
      "    description: DOWNWARD SHORT WAVE FLUX AT GROUND SURFACE\n",
      "    units: W m-2\n",
      "    stagger: \n",
      "    coordinates: XLONG XLAT\n",
      "unlimited dimensions: Time\n",
      "current shape = (24, 320, 256)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('PREC_ACC_NC', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 PREC_ACC_NC(Time, south_north, west_east)\n",
      "    description: ACCUMULATED GRID SCALE  PRECIPITATION OVER prec_acc_dt PERIODS OF TIME\n",
      "    units: mm\n",
      "    stagger: \n",
      "    coordinates: XLONG XLAT\n",
      "unlimited dimensions: Time\n",
      "current shape = (24, 320, 256)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('ZNT', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 ZNT(Time, south_north, west_east)\n",
      "    description: TIME-VARYING ROUGHNESS LENGTH\n",
      "    units: m\n",
      "    stagger: \n",
      "    coordinates: XLONG XLAT\n",
      "unlimited dimensions: Time\n",
      "current shape = (24, 320, 256)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "print(wrf_data.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('COSALPHA', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 COSALPHA(Time, south_north, west_east)\n",
      "    FieldType: 104\n",
      "    MemoryOrder: XY \n",
      "    description: Local cosine of map rotation\n",
      "    units: \n",
      "    stagger: \n",
      "    coordinates: XLONG XLAT\n",
      "unlimited dimensions: Time\n",
      "current shape = (1, 320, 256)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('HGT', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 HGT(Time, south_north, west_east)\n",
      "    FieldType: 104\n",
      "    MemoryOrder: XY \n",
      "    description: Terrain Height\n",
      "    units: m\n",
      "    stagger: \n",
      "    coordinates: XLONG XLAT\n",
      "unlimited dimensions: Time\n",
      "current shape = (1, 320, 256)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('LANDMASK', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 LANDMASK(Time, south_north, west_east)\n",
      "    FieldType: 104\n",
      "    MemoryOrder: XY \n",
      "    description: LAND MASK (1 FOR LAND, 0 FOR WATER)\n",
      "    units: \n",
      "    stagger: \n",
      "    coordinates: XLONG XLAT\n",
      "unlimited dimensions: Time\n",
      "current shape = (1, 320, 256)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('LU_INDEX', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 LU_INDEX(Time, south_north, west_east)\n",
      "    FieldType: 104\n",
      "    MemoryOrder: XY \n",
      "    description: LAND USE CATEGORY\n",
      "    units: \n",
      "    stagger: \n",
      "    coordinates: XLONG XLAT\n",
      "unlimited dimensions: Time\n",
      "current shape = (1, 320, 256)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('SINALPHA', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 SINALPHA(Time, south_north, west_east)\n",
      "    FieldType: 104\n",
      "    MemoryOrder: XY \n",
      "    description: Local sine of map rotation\n",
      "    units: \n",
      "    stagger: \n",
      "    coordinates: XLONG XLAT\n",
      "unlimited dimensions: Time\n",
      "current shape = (1, 320, 256)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('XLAT', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 XLAT(Time, south_north, west_east)\n",
      "    FieldType: 104\n",
      "    MemoryOrder: XY \n",
      "    description: LATITUDE, SOUTH IS NEGATIVE\n",
      "    units: degree_north\n",
      "    stagger: \n",
      "unlimited dimensions: Time\n",
      "current shape = (1, 320, 256)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      "), ('XLONG', <class 'netCDF4._netCDF4.Variable'>\n",
      "float32 XLONG(Time, south_north, west_east)\n",
      "    FieldType: 104\n",
      "    MemoryOrder: XY \n",
      "    description: LONGITUDE, WEST IS NEGATIVE\n",
      "    units: degree_east\n",
      "    stagger: \n",
      "unlimited dimensions: Time\n",
      "current shape = (1, 320, 256)\n",
      "filling on, default _FillValue of 9.969209968386869e+36 used\n",
      ")])\n"
     ]
    }
   ],
   "source": [
    "print(mask_data.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[33.824394 33.825592 33.82678  ... 33.82678  33.825592 33.824394]\n",
      "  [33.85127  33.85247  33.85365  ... 33.85365  33.85247  33.85127 ]\n",
      "  [33.878147 33.879337 33.880527 ... 33.880527 33.879337 33.878147]\n",
      "  ...\n",
      "  [42.35921  42.360554 42.36189  ... 42.36189  42.360554 42.35921 ]\n",
      "  [42.386093 42.38743  42.38876  ... 42.38876  42.38743  42.386093]\n",
      "  [42.412956 42.41429  42.41563  ... 42.41563  42.41429  42.412956]]]\n",
      "[[[-125.13013  -125.09778  -125.06543  ... -116.93457  -116.90222\n",
      "   -116.86987 ]\n",
      "  [-125.13158  -125.09921  -125.066864 ... -116.933136 -116.90079\n",
      "   -116.86842 ]\n",
      "  [-125.133026 -125.10065  -125.06827  ... -116.93173  -116.89935\n",
      "   -116.866974]\n",
      "  ...\n",
      "  [-125.644516 -125.608154 -125.57178  ... -116.42822  -116.391846\n",
      "   -116.355484]\n",
      "  [-125.64633  -125.609955 -125.57358  ... -116.42642  -116.390045\n",
      "   -116.35367 ]\n",
      "  [-125.64816  -125.61177  -125.57538  ... -116.42462  -116.38823\n",
      "   -116.35184 ]]]\n"
     ]
    }
   ],
   "source": [
    "# Get the horizontal grid\n",
    "lats = mask_data.variables['XLAT'][:]    # degree_north\n",
    "longs = mask_data.variables['XLONG'][:]  # degree_east\n",
    "print(lats)\n",
    "print(longs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Wind speed\n",
    "u10 = wrf_data.variables['U10'][:]   # U component of wind at 10m, in m/s\n",
    "v10 = wrf_data.variables['V10'][:]   # V component of wind at 10m, in m/s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LAT** and **LON** are numpy arrays of shape (x,y)\n",
    "\n",
    "**U** and **V** are numpy arrays of shape (time,x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format the time values from bytes into strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'0' b'0' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'0' b'1' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'0' b'2' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'0' b'3' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'0' b'4' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'0' b'5' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'0' b'6' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'0' b'7' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'0' b'8' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'0' b'9' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'1' b'0' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'1' b'1' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'1' b'2' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'1' b'3' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'1' b'4' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'1' b'5' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'1' b'6' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'1' b'7' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'1' b'8' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'1' b'9' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'2' b'0' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'2' b'1' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'2' b'2' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']\n",
      " [b'2' b'0' b'1' b'7' b'-' b'1' b'0' b'-' b'0' b'8' b'_' b'2' b'3' b':'\n",
      "  b'0' b'0' b':' b'0' b'0']]\n",
      "[bytearray(b'2017-10-08_00:00:00'), bytearray(b'2017-10-08_01:00:00'), bytearray(b'2017-10-08_02:00:00'), bytearray(b'2017-10-08_03:00:00'), bytearray(b'2017-10-08_04:00:00'), bytearray(b'2017-10-08_05:00:00'), bytearray(b'2017-10-08_06:00:00'), bytearray(b'2017-10-08_07:00:00'), bytearray(b'2017-10-08_08:00:00'), bytearray(b'2017-10-08_09:00:00'), bytearray(b'2017-10-08_10:00:00'), bytearray(b'2017-10-08_11:00:00'), bytearray(b'2017-10-08_12:00:00'), bytearray(b'2017-10-08_13:00:00'), bytearray(b'2017-10-08_14:00:00'), bytearray(b'2017-10-08_15:00:00'), bytearray(b'2017-10-08_16:00:00'), bytearray(b'2017-10-08_17:00:00'), bytearray(b'2017-10-08_18:00:00'), bytearray(b'2017-10-08_19:00:00'), bytearray(b'2017-10-08_20:00:00'), bytearray(b'2017-10-08_21:00:00'), bytearray(b'2017-10-08_22:00:00'), bytearray(b'2017-10-08_23:00:00')]\n"
     ]
    }
   ],
   "source": [
    "nctime = wrf_data.variables['times'][:] \n",
    "print(nctime)\n",
    "nctime_str = [bytearray(x) for x in nctime]\n",
    "print(nctime_str[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2017-10-08_00:00:00', '2017-10-08_01:00:00', '2017-10-08_02:00:00', '2017-10-08_03:00:00', '2017-10-08_04:00:00', '2017-10-08_05:00:00', '2017-10-08_06:00:00', '2017-10-08_07:00:00', '2017-10-08_08:00:00', '2017-10-08_09:00:00', '2017-10-08_10:00:00', '2017-10-08_11:00:00', '2017-10-08_12:00:00', '2017-10-08_13:00:00', '2017-10-08_14:00:00', '2017-10-08_15:00:00', '2017-10-08_16:00:00', '2017-10-08_17:00:00', '2017-10-08_18:00:00', '2017-10-08_19:00:00', '2017-10-08_20:00:00', '2017-10-08_21:00:00', '2017-10-08_22:00:00', '2017-10-08_23:00:00']\n"
     ]
    }
   ],
   "source": [
    "times_str = [x.decode(\"utf-8\") for x in nctime_str]\n",
    "print(times_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract winds at a particular lat,lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ma.core.MaskedArray'> (1, 320, 256)\n",
      "<class 'numpy.ma.core.MaskedArray'> (1, 320, 256)\n",
      "<class 'list'> 24\n",
      "<class 'numpy.ma.core.MaskedArray'> (24, 320, 256)\n",
      "<class 'numpy.ma.core.MaskedArray'> (24, 320, 256)\n"
     ]
    }
   ],
   "source": [
    "print(type(lats),lats.shape)\n",
    "print(type(longs),longs.shape)\n",
    "print(type(times_str), len(times_str) )\n",
    "print(type(u10),u10.shape)\n",
    "print(type(v10),v10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 143, 100)\n"
     ]
    }
   ],
   "source": [
    "lat_obs = 37.7644\n",
    "long_obs = -121.9540\n",
    "coordinates = np.unravel_index((np.abs(lats - lat_obs) + \n",
    "                                np.abs(longs - long_obs)).argmin(), \n",
    "                               lats.shape)\n",
    "print(coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.751087 -121.938324\n"
     ]
    }
   ],
   "source": [
    "# Validate\n",
    "print(lats[coordinates], longs[coordinates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find pixel-range based on the provided lat-lon\n",
    "def find_pixels(lat_array,  # Array with latitudes  in the NetCDF file\n",
    "                lon_array,  # Array with longitudes in the NetCDF file\n",
    "                mylat,     # Latitude value one to be matched to a pixel\n",
    "                mylon):    # Longitude value to be matched to a pixel\n",
    "    \"Outputs: coordinates: (time_index, x_pixel_index, y_pixel_indes)\"\n",
    "    \n",
    "    coordinates = np.unravel_index((np.abs(lat_array - mylat) + \n",
    "                                    np.abs(lon_array - mylon)).argmin(), \n",
    "                                   lat_array.shape)\n",
    "    \n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 143, 100) (143, 100)\n",
      "37.751087 -121.938324\n"
     ]
    }
   ],
   "source": [
    "# Validate\n",
    "san_ramon_lat = 37.7644\n",
    "san_ramon_lon = -121.9540\n",
    "pixel_coordinates = find_pixels(lat_array=lats, \n",
    "                          lon_array=longs,\n",
    "                          mylat=san_ramon_lat,\n",
    "                          mylon=san_ramon_lon)\n",
    "print(pixel_coordinates, pixel_coordinates[1:])\n",
    "print(lats[pixel_coordinates], longs[pixel_coordinates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u10: [ 1.43788     1.0371825  -1.1281722   0.24685748  0.7650842   1.6698962\n",
      "  1.8408111   1.7607706   1.5985771   1.933602    2.0516458   2.2162855\n",
      "  1.6295602   1.6050293   1.3692856   2.303459    2.0056553   1.7469375\n",
      "  1.9214604   2.5303571   2.8808727   2.6294363   1.6649076   1.3128626 ]\n",
      "v10: [ 0.3964637  -0.66054946  0.142182    1.6731651   1.530715    0.08108234\n",
      " -1.5829245  -2.7210696  -0.1800741  -3.9051445  -6.186078   -7.140886\n",
      " -6.8337164  -6.7692394  -6.7861214  -7.44211    -7.4399447  -7.3176064\n",
      " -6.3386025  -7.175972   -6.486578   -5.3904963  -4.635575   -5.8391914 ]\n",
      "[1.4915369 1.2296638 1.1370964 1.6912776 1.7112691 1.6718636 2.4278047\n",
      " 3.2410698 1.6086875 4.3576336 6.517424  7.476909  7.025322  6.9569187\n",
      " 6.9228888 7.790438  7.7055454 7.523241  6.623435  7.6090264 7.0975432\n",
      " 5.997615  4.925492  5.9849615]\n"
     ]
    }
   ],
   "source": [
    "# List wind values\n",
    "u10_time = u10[:,pixel_coordinates[1], pixel_coordinates[2]]\n",
    "print('u10:', u10_time)\n",
    "v10_time = v10[:,pixel_coordinates[1], pixel_coordinates[2]]\n",
    "print('v10:', v10_time)\n",
    "speed_time = (u10_time**2 + v10_time**2)**0.5\n",
    "print(speed_time)\n",
    "\n",
    "# I manualy validated for speed_time[0] and speed_time[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Shape files with PyShp\n",
    "\n",
    "References:\n",
    "    \n",
    "    https://pypi.org/project/pyshp/\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import shapefile\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data (simply specify the base filename of the shapefile)\n",
    "sf_data = shapefile.Reader(SHAPE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 key files associated with any and all shapefiles:\n",
    "\n",
    "    .shp: the file that contains the geometry for all features.\n",
    "    .shx: the file that indexes the geometry.\n",
    "    .dbf: the file that stores feature attributes in a tabular format.\n",
    "\n",
    "Note that, sometimes, a shapefile will have other associated files including:\n",
    "\n",
    "    .prj: the file that contains information on projection format including the coordinate system and projection information. It is a plain text file describing the projection using well-known text (WKT) format.\n",
    "    .sbn and .sbx: the files that are a spatial index of the features.\n",
    "    .shp.xml: the file that is the geospatial metadata in XML format, (e.g. ISO 19115 or XML format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sf_data = shapefile.Reader(SHAPE_PATH)  # Open, read, and close the shapefiles\n",
    "shapes = sf_data.shapes()  # Geometry: shp file with points, polygons, or polines\n",
    "fields = sf_data.fields    # Atributes: shx file with headers. This file is optional for reading.\n",
    "records= sf_data.records() # Records: dbf file with contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('DeletionFlag', 'C', 1, 0), ['OBJECTID', 'N', 10, 0], ['FDCZ', 'C', 10, 0], ['Shape_Leng', 'F', 19, 11], ['Shape_Area', 'F', 19, 11]]\n"
     ]
    }
   ],
   "source": [
    "print(fields)\n",
    "#print('NumShapes=',len(shapes))\n",
    "#[[longi,lati]] = shapes[3].points\n",
    "#print(shapes[3].points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapefile Reader\n",
      "    9 shapes (type 'POLYGON')\n",
      "    9 records (5 fields)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(sf_data)\n",
    "print(sf_data.shapeType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape types are represented by numbers between 0 and 31 as defined by the shapefile specification and listed below (existing shape types are not sequential):\n",
    "\n",
    "    NULL = 0\n",
    "    POINT = 1\n",
    "    POLYLINE = 3\n",
    "    POLYGON = 5\n",
    "    MULTIPOINT = 8\n",
    "    POINTZ = 11\n",
    "    POLYLINEZ = 13\n",
    "    POLYGONZ = 15\n",
    "    MULTIPOINTZ = 18\n",
    "    POINTM = 21\n",
    "    POLYLINEM = 23\n",
    "    POLYGONM = 25\n",
    "    MULTIPOINTM = 28\n",
    "    MULTIPATCH = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Record #0: [1, '2', 1390085.42269, 17666548994.1],\n",
       " Record #1: [2, '7', 729435.83367, 15430289623.4],\n",
       " Record #2: [3, '4', 958413.83175, 9903732149.59],\n",
       " Record #3: [4, '8', 1449745.07201, 30082596718.2],\n",
       " Record #4: [5, '1', 723620.623482, 13363523334.2],\n",
       " Record #5: [6, 'CV', 1683096.83967, 43468179793.4],\n",
       " Record #6: [7, '6', 1499360.10436, 35517704400.4],\n",
       " Record #7: [8, '5', 1025812.3241, 23459612723.5],\n",
       " Record #8: [10, '3', 1108384.9473, 14491501654.0]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_data.records()[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('DeletionFlag', 'C', 1, 0),\n",
       " ['OBJECTID', 'N', 10, 0],\n",
       " ['FDCZ', 'C', 10, 0],\n",
       " ['Shape_Leng', 'F', 19, 11],\n",
       " ['Shape_Area', 'F', 19, 11]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf_data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['591356.500', '3818301.180', '799052.350', '4079924.970']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=sf_data.shape(2)\n",
    "# Read the bbox of the 1th shape to verify\n",
    "# Round coordinates to 3 decimal places\n",
    "['%.3f' % coord for coord in s.bbox]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why these doesn't look like Latitudes and Longitudes?**\n",
    "\n",
    "The reason is that we need to read the *.prj projection file to do the conversion. However, PyShp does not handle projections.\n",
    "\n",
    "**==> Use a different tool**, e.g., GeoPandas or Fiona, or osgeo, or ogr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Shape files with GeoPandas\n",
    "\n",
    "References:\n",
    "\n",
    "    https://pypi.org/project/geopandas/\n",
    "    https://geopandas.org/projections.html\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = geopandas.read_file(geopandas.datasets.get_path('fdcz_pl'))\n",
    "df = geopandas.read_file(\"fdcz_pl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'init': 'epsg:26910'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coordinate Reference Systems\n",
    "df.crs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 5) Index(['OBJECTID', 'FDCZ', 'Shape_Leng', 'Shape_Area', 'geometry'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.shape, df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OBJECTID FDCZ    Shape_Leng    Shape_Area  \\\n",
      "0         1    2  1.390085e+06  1.766655e+10   \n",
      "1         2    7  7.294358e+05  1.543029e+10   \n",
      "2         3    4  9.584138e+05  9.903732e+09   \n",
      "3         4    8  1.449745e+06  3.008260e+10   \n",
      "4         5    1  7.236206e+05  1.336352e+10   \n",
      "5         6   CV  1.683097e+06  4.346818e+10   \n",
      "6         7    6  1.499360e+06  3.551770e+10   \n",
      "7         8    5  1.025812e+06  2.345961e+10   \n",
      "8        10    3  1.108385e+06  1.449150e+10   \n",
      "\n",
      "                                            geometry  \n",
      "0  MULTIPOLYGON (((519551.640 4297033.400, 519732...  \n",
      "1  POLYGON ((672018.920 4264044.500, 664624.110 4...  \n",
      "2  POLYGON ((617417.000 4079543.780, 617489.360 4...  \n",
      "3  POLYGON ((630040.320 4568638.610, 630162.520 4...  \n",
      "4  POLYGON ((501997.180 4452796.830, 501999.880 4...  \n",
      "5  POLYGON ((572281.380 4445705.500, 573752.440 4...  \n",
      "6  POLYGON ((897800.710 3869673.770, 898319.660 3...  \n",
      "7  POLYGON ((652128.040 4116463.650, 652149.990 4...  \n",
      "8  MULTIPOLYGON (((595338.853 4211024.272, 604536...  \n"
     ]
    }
   ],
   "source": [
    "print(df)#.shape)['geometry'], df.shape['geometry'].x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-e94f23fb7464>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-e94f23fb7464>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    POR ACA VOY\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "POR ACA VOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for shape in range(df.shape[0]):\n",
    "    df.loc[shape]['lon'] = df[shape]['geometry'].x\n",
    "    df.loc[shape]['lat'] = df[shape]['geometry'].y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "ax = df.plot()\n",
    "\n",
    "ax.set_title(\"epsg:26910 (lat/lon)\");\n",
    "\n",
    "# Reproject to Mercator (after dropping Antartica)\n",
    "world = world[(world.name != \"Antarctica\") & (world.name != \"Fr. S. Antarctic Lands\")]\n",
    "\n",
    "world = world.to_crs(\"EPSG:3395\") # world.to_crs(epsg=3395) would also work\n",
    "\n",
    "ax = world.plot()\n",
    "\n",
    "ax.set_title(\"Mercator\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert shapefile data into a Pandas dataframe\n",
    "def read_shapefile(sf):\n",
    "    \"\"\"\n",
    "    Read a shapefile into a Pandas dataframe with a 'coords' \n",
    "    column holding the geometry information. This uses the pyshp\n",
    "    package\n",
    "    \"\"\"\n",
    "    fields = [x[0] for x in sf.fields][1:]\n",
    "    records = sf.records()\n",
    "    shps = [s.points for s in sf.shapes()]\n",
    "    df = pd.DataFrame(columns=fields, data=records)\n",
    "    df = df.assign(coords=shps)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df = read_shapefile(sf_data)\n",
    "print(sf_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
